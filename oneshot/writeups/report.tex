\documentclass{article}
\usepackage{geometry}[1in]
\usepackage{amsmath}
\usepackage{amsfonts}

\newcommand{\R}{{\mathbb{R}}}
\newcommand{\Z}{{\mathbb{Z}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\softmax}{soft\,max}

\title{The Reverse Ising Problem}
\author{Andrew Moore}
\date{Summer 2023}
\begin{document}
\maketitle

\section{Introduction}

This document assumes that the reader is already familiar with the basics of the reverse Ising problem. It is means to cover some broad conceptual observations and new developments.

\subsection{Problem Formulations}

As typically stated, the reverse Ising problem is about designing a Sherrington-Kirkpatrick Hamiltonian on a discrete system of binary spins such that for each fixed configuration of the first $N$ spins (called an `input level'), the minimum energy state is perscribed by a chosen function $f: \Sigma^N \longrightarrow \Sigma^M$. We chosen to focus on the construction of Ising circuitry where $f$ is binary integer multiplication, but most of the work on this problem is independent of the choice of $f$. It should be noted that there are some functions which are easy to model (addition, for example), while some functions are extremely difficult. Theoretical justifications for these claims will be supplied later. Multiplication is likely somewhere in the middle.

As stated, this problem shares some important similarities with a few others. Note that while in the traditional formulation the first $N$ spins are fixed by the user, we could instead double each of the input spins into a highly ferromagnetic pair, and obtain an isolated Ising system with the same dynamics. In this formulation, setting the temperature to zero results in the classical Hopfield network, with the desired input/output pairs corresponding to stored memory patterns. Alternatively, if $M=1$, then a quadratic Hamiltonian satisfying the Ising constraints is equivalent to a hard-constraint SVM, while a relaxed Ising problem with artificial variables is equivalent to an unregularized soft-constraint SVM.

\subsection{Storage Capacity Estimates}
It is useful at this point to dispel a common misconception. In most of our circuits, we are attempting to load a perscribed answer $x, f(x)$ as a ground state given each input configuration $x$. If the input spins are converted to ferromagnetic pairs to give an isolated system, then this translates to storing $2^N$ patterns in a Hopfield network with $2N + M + A$ neurons. Conventional wisdom says that the maximum storage capacity of a Hopfield network with $k$ neurons is roughly $0.139k$, suggesting that $2^N \simeq 0.139(2N + M + A)$, and hence $A \simeq 7.19(2^N - 0.139(2N + M)) \sim \mathcal{O}(2^N)$. If this conventional wisdom were actually accurate, in other words, the project is completely dead. However, it is simply not true that the storage capacity of the Hopfield network is $0.139k$. That estimate refers to the number of `linearly indepdentent' states which can be stored using the Hebbian learning rule. Using better learning rules can up that number to $k-1$, but that is still linear. However, the key issue is with the notion of so-called `linear independence'. In fact, if we do not require our stored states to be independent in this sense, we can store exponentially many states. A famous result of Parisi shows that the expected number of ground states in an Ising system with i.i.d. Gaussian interaction strength is roughly $2^{0.2k}$. In an ideal world, we could make use of all these ground states. This would mean that $2^N \simeq 2^{0.2(2N + M + A)}$, so $N \simeq 0.2(2N + M + A)$, so $A \simeq 1.6N - 0.2M$. In the case of $n\times n$ multiplication, $N = M = 2n$, so we would get $A \simeq 2.8n$. This back-of-the-envelope calculation shows that the problem is at least in theory possible with sub-exponential number of spins, though of course the actual scaling of minimum $A$ depends on the complexity of $f$. 

\subsection{Baseline Solutions for Multiplication}

It is known from classical circuit design that multiplication circuits can be tiled to create larger multiplication circuits. In particular, we can uses 4 $n\times n$ multiplication circuits, together with a multi-op adder, to create $2n \times 2n$ multiplication. This suggests that the number of auxilliaries generated by this method scales quadratically with $n$. Whether or not such solutions are actually practical remains undetermined, as the need for forward information flow could cause high dynamic range of the Hamiltonian coefficients. However, this gives us a baseline for problem difficulty. It is hard not to notice that the classical difficulty of multiplication is indeed $n^2$, with (in practice useless) algorithms involving FFT known to push this down to $n\log n$. Essentially, this means that working on the reverse Ising problem is only worth it if $A$ can be made to scale sub-quadratically, and gives us reason to believe that $A \sim \mathcal{O}(n\log n)$ is the best we will be able to do. These are, however, just guesses.

\subsection{The Naive Approach is Impossible}

The problem of finding feasible auxilliary arrays is a mixed integer-linear programming problem, a class of problem which is known in general to be NP-hard. We know of no way to evaluate whether an auxilliary array is feasible other than to run the linear program. Linear program difficulty can be measured by the size of the constraint matrix. Said constraint matrix will have $2^{N + M + A} - 2^{N}$ rows and around $M+A+(N+M+A-1)(N+M+A)/2$ columns, which in the case of $n\times n$ multiplication gives an LP difficulty of roughly $\mathcal{O}((4n+A)^2 2^{4n}2^A)$. Even if $A \sim \mathcal{O}(n\log n)$ is possible, we would have an LP difficulty of $\mathcal{O}(n^2\log^2(n) 2^n n^n)$. Since each auxilliary vector needs to be assigned a binary value at each input level, the number of possible auxilliary arrays is $2^{A2^N}$, resulting in the total brute-force search difficulty being around $\mathcal{O}(n^2\log^2(n)2^nn^{n +n2^{2n+1}})$, which is absurdly impossible. To many any progress at all, we need to both restrict our aux array search space and find ways to acheive non-exponential scaling in the LP problem.


\end{document}
